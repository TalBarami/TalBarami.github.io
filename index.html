<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Tal Barami</title>
    <link rel="stylesheet" type="text/css"
        href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
    <link rel="stylesheet" type="text/css" href="main.css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119312378-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-119312378-1');
    </script>
</head>

<body>
    <div id="content">
        <div class="cv-story-wrapper">
			<div class="g-row">
				<header class="g-col fl-none g-column cv-header">
					<div class="g-col g-column">
						<h1 class="g-col fl-none fs-headline">
							<strong>Tal Barami</strong>
						</h1>
						<div class="g-col fl-none g-row _gutters-12 cv-meta">
							<div class="g-col ai-center fl-none">
								<img src="github.svg" role="img" class="svg-icon" title="GitHub">
								<a href="https://github.com/TalBarami" rel="me" class="url">GitHub</a>
							</div>
							<div class="g-col ai-center fl-none">
								<img src="linkedin.svg" role="img" class="svg-icon" title="Phone">
								<a href="https://www.linkedin.com/in/tal-barami/" rel="me" class="url">LinkedIn</a>
							</div>
                            <div class="g-col ai-center fl-none">
                                <img src="gmail.png" role="img" class="svg-icon" title="Mail">
								<a href="mailto:talbaramii@gmail.com" rel="me" class="url">Mail</a>
							</div>
						</div>
					</div>
					<div class="g-col g-column fl-none fs-body1 cv-intro-statement">
						<p>Ph.D. student in the department of <a href="https://in.bgu.ac.il/en/natural_science/cs/Pages/default.aspx" rel="me" class="computer science">computer science</a> at Ben Gurion University of the Negev.
						Researcher, interested in solving graphics and vision problems with algorithms and data.</p>
						<div class="g-col g-row fl-none ff-row-wrap">
							<span class="post-tag">Coding</span>
                            <span class="post-tag">Reading</span>
							<span class="post-tag">Traveling</span>
							<span class="post-tag">Sports</span>
							<span class="post-tag">Gaming</span>
						</div>
					</div>
				</header>
				<div class="g-col g-column _gutters-48 cv-story">
					<img src="pic.jpg" role="img" width=180 height=auto title="">
				</div>
			</div>
            <div class="g-row">
                <div class="g-col g-column _gutters-48 cv-story">
                    <section class="g-col fl-none g-column cv-section" id="Education">
                        <header class="g-col fl-none">
                            <h2 class="fs-category">Education</h2>
                        </header>
                        <div class="g-column _gutters-24">
                            <article class="g-col g-row cv-story-item highlight first last">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="bgu.png" role="img" class="cv-image" title="Ben Gurion University of the Negev">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading"><strong>Computer Science, Ph.D.</strong>
                                    </h3>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Ben-Gurion University of the Negev</h4>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Advisors: Prof. Ilan Dinstein, Dr. Omri Azencot</h4>
                                    <div class="g-col fl-none g-row _gutters fs-caption cv-item-time">
                                        <span class="g-col fl-none">2020 &mdash; Present</span>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Behavior Analysis</span>
                                        <span class="post-tag">Autism Research</span>
                                        <span class="post-tag">Medical Data</span>
                                        <span class="post-tag">Applicative Research</span>
                                        <span class="post-tag">Sequential Data</span>
                                        <span class="post-tag">Representation Learning</span>
                                        <span class="post-tag">Disentanglement</span>
                                        <span class="post-tag">Facial Expressions Analysis</span>
                                        <span class="post-tag">Treatment Effect Estimation</span>
                                        <span class="post-tag">Saliency Maps</span>
                                    </div>
                                </div>
                            </article>
                            <article class="g-col g-row cv-story-item highlight first last">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="bgu.png" role="img" class="cv-image" title="Ben Gurion University of the Negev">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading"><strong>Computer Science, M.Sc.</strong></h3>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Ben-Gurion University of the Negev</h4>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Advisors: Prof. Ilan Dinstein, Prof. Andrei Sharf</h4>
                                    <div class="g-col fl-none g-row _gutters fs-caption cv-item-time">
                                        <span class="g-col fl-none">2018 &mdash; 2020</span>
                                    </div>
				<div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Artificial Intelligence</span>
                                        <span class="post-tag">Deep Learning</span>
                                        <span class="post-tag">Computer Vision</span>
					<span class="post-tag">Video Processing</span>
                                        <span class="post-tag">Object Detection</span>
                                        <span class="post-tag">Video Games Design</span>
                                        <span class="post-tag">Action Recognition</span>
                                    </div>
                                </div>
                            </article>
                            <article class="g-col g-row cv-story-item highlight first last">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="bgu.png" role="img" class="cv-image" title="Ben Gurion University of the Negev">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading"><strong>Software Engineering, B.E.</strong>
                                    </h3>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Ben-Gurion University
                                        of the Negev</h4>
                                    <div class="g-col fl-none g-row _gutters fs-caption cv-item-time">
                                        <span class="g-col fl-none">2014 &mdash; 2018</span>
                                    </div>
									<div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Computer Graphics</span>
                                        <span class="post-tag">Software Design</span>
                                        <span class="post-tag">Virtual Reality</span>
										<span class="post-tag">Data Science</span>
                                    </div>
                                </div>
                            </article>
                        </div>
                    </section>
                    <section class="g-col fl-none g-column cv-section" id="Publications & Projects">
                        <header class="g-col fl-none">
                            <h2 class="fs-category">Publications & Projects:</h2>
                        </header>
                        <div class="g-column _gutters-24">

                            <!-- Multi-factor Sequential Disentanglement project -->
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo-blank">
                                        <svg aria-hidden="true" class="svg-icon iconProfileArticle" width="24" height="24" viewBox="0 0 24 24">
                                            <path class="st0" d="M13,3v6h6L13,3z M13,11c-1.1,0-2-0.9-2-2V2H5C4.5,2,4,2.5,4,3v18c0,0.5,0.5,1,1,1h14c0.5,0,1-0.5,1-1V11H13z"></path>
                                        </svg>
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="https://github.com/TalBarami/MSD" rel="nofollow"
                                           title="Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations">
                                            <strong>Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations</strong>
                                        </a>
                                    </h3>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>Tal Barami, Nimrod Berman, Ilan Naiman, Amos Haviv Hason, Rotem Ezra, Omri Azencot</p>
                                        <p>
                                            Learning disentangled representations in sequential data is crucial for vision, audio, and time series.
                                            Real-world sequences involve <em>multiple interacting semantic factors</em>, but most prior work limits
                                            itself to two (static/dynamic). We introduce the first standardized benchmark for <strong>multi-factor
                                            sequential disentanglement</strong> across six diverse datasets (video, audio, time-series), with modular
                                            tools for dataset integration, model development, and factor-aware evaluation metrics.
                                        </p>
                                        <p>
                                            We propose a post-hoc <strong>Latent Exploration Stage (LES)</strong> that aligns latent dimensions with
                                            semantic factors, and a <strong>Koopman-inspired model</strong> that achieves state-of-the-art results.
                                            We further show that <strong>Vision-Language Models</strong> can automate dataset annotation and act as
                                            zero-shot disentanglement evaluators—reducing the need for manual labels and human intervention.
                                            Together, these contributions create a robust, scalable foundation for advancing multi-factor sequential
                                            disentanglement.
                                        </p>
                                        <p>
                                            <a href="https://arxiv.org/abs/xxxx.xxxxx" rel="nofollow">Paper (arXiv)</a> &middot;
                                            <a href="https://github.com/azencot-group/MSD-Benchmark" rel="nofollow">
                                                <img src="github.svg" role="img" class="svg-icon" style="width:22px; height:22px; vertical-align:middle; margin-bottom: 5px">
                                                Code & Benchmark
                                            </a>
                                        </p>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Disentanglement</span>
                                        <span class="post-tag">Sequential Data</span>
                                        <span class="post-tag">Video</span>
                                        <span class="post-tag">Audio</span>
                                        <span class="post-tag">Time Series</span>
                                        <span class="post-tag">Latent Space Exploration</span>
                                        <span class="post-tag">Koopman Models</span>
                                        <span class="post-tag">VLM Evaluation</span>
                                        <span class="post-tag">Benchmarking</span>
                                    </div>
                                </div>
                            </article>
                            <!-- End of Multi-factor Sequential Disentanglement project -->

                            <!-- Facial Expressions Analysis project -->
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo-blank">
                                        <svg aria-hidden="true" class="svg-icon iconProfileArticle" width="24" height="24" viewBox="0 0 24 24">
                                            <path class="st0"
                                                  d="M13,3v6h6L13,3z M13,11c-1.1,0-2-0.9-2-2V2H5C4.5,2,4,2.5,4,3v18c0,0.5,0.5,1,1,1h14c0.5,0,1-0.5,1-1V11H13z">
                                            </path>
                                        </svg>
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="https://www.biorxiv.org/content/10.1101/2025.05.14.653948v1.abstract" rel="nofollow"
                                           title="Using computer vision to quantify facial expressions of children with autism during naturalistic social interactions">
                                            <strong>Using computer vision to quantify facial expressions of children with autism during naturalistic social interactions</strong>
                                        </a>
                                    </h3>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>Liora Manelis, Tal Barami, Michal Ilan, Gal Meiri, Idan Menashe, Elizabeth Soskin, Carmel Sofer, Ilan Dinstein</p>
                                        <p>
                                            We analyzed over 5 million video frames from 100 children (72 autistic, 28 controls; ages 2–7)
                                            recorded during ADOS-2 assessments. Facial expressions were quantified using three leading analysis
                                            tools (iMotions, FaceReader, Py-Feat), enabling objective comparisons across algorithms and groups.
                                            Despite substantial variability between tools, all three consistently showed no group differences in
                                            the <em>quantity</em> of facial expressions, suggesting that atypical expression use in autism relates
                                            more to quality, timing, and social context than to overall frequency.
                                        </p>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Facial Expressions</span>
                                        <span class="post-tag">Autism</span>
                                        <span class="post-tag">Computer Vision</span>
                                        <span class="post-tag">Behavior Analysis</span>
                                        <span class="post-tag">Py-Feat</span>
                                        <span class="post-tag">iMotions</span>
                                        <span class="post-tag">FaceReader</span>
                                        <span class="post-tag">ADOS-2</span>
                                    </div>
                                </div>
                            </article>
                            <!-- End of Facial Expressions Analysis project -->

                            <!-- Stereotypical Movements project -->
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo-blank">
                                        <svg aria-hidden="true" class="svg-icon iconProfileArticle" width="24" height="24" viewBox="0 0 24 24">
                                            <path class="st0"
                                                  d="M13,3v6h6L13,3z M13,11c-1.1,0-2-0.9-2-2V2H5C4.5,2,4,2.5,4,3v18c0,0.5,0.5,1,1,1h14c0.5,0,1-0.5,1-1V11H13z">
                                            </path>
                                        </svg>
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823635" rel="nofollow"
                                           title="Automated Analysis of Stereotypical Movements in Videos of Children With Autism Spectrum Disorder">
                                            <strong>Automated Analysis of Stereotypical Movements in Videos of Children With Autism Spectrum Disorder</strong>
                                        </a>
                                    </h3>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>Tal Barami, Liora Manelis-Baram, Hadas Kaiser, Michal Ilan, Aviv Slobodkin, Ofri Hadashi, Dor Hadad, Omri Azencot, Andrei Sharf, Ilan Dinstein</p>
                                        <p>
                                            We developed <strong>ASDMotion</strong>, the first large-scale open-source tool for detecting and
                                            quantifying stereotypical motor movements (SMMs) in children with autism. Trained on over 200
                                            clinical assessments with expert annotations, ASDMotion combines deep learning with pose-based
                                            analysis to identify repetitive behaviors such as hand flapping and body rocking.
                                        </p>
                                        <p>
                                            The system achieves <strong>over 92% recall</strong> and strong alignment with expert ratings,
                                            enabling scalable and objective measurement of a core symptom of autism. Beyond its immediate
                                            clinical utility, ASDMotion provides a rich dataset and benchmark for advancing automated behavior
                                            analysis in naturalistic settings, opening the door to more reliable diagnostics, treatment
                                            monitoring, and research on developmental disorders.
                                        </p>
                                        <p>
                                            <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823635" rel="nofollow">Paper</a> &middot;
                                            <a href="https://github.com/Dinstein-Lab/ASDMotion" rel="nofollow">
                                                <img src="github.svg" role="img" class="svg-icon" style="width:22px; height:22px; vertical-align:middle; margin-bottom: 5px">
                                                Code
                                            </a>
                                        </p>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Autism</span>
                                        <span class="post-tag">Stereotypical Movements</span>
                                        <span class="post-tag">Computer Vision</span>
                                        <span class="post-tag">Behavior Analysis</span>
                                        <span class="post-tag">Pose Estimation</span>
                                        <span class="post-tag">Deep Learning</span>
                                    </div>
                                </div>
                            </article>
                            <!-- End of Stereotypical Movements project -->

                            <!-- 3D Pose Estimation from 3D Data project -->
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo-blank">
                                        <svg aria-hidden="true" class="svg-icon iconProfileArticle" width="24"
                                             height="24" viewBox="0 0 24 24">
                                            <path class="st0"
                                                  d="M13,3v6h6L13,3z M13,11c-1.1,0-2-0.9-2-2V2H5C4.5,2,4,2.5,4,3v18c0,0.5,0.5,1,1,1h14c0.5,0,1-0.5,1-1V11H13z">
                                            </path>
                                        </svg>
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="https://proc.3dbody.tech/abstracts/2023/2342hod.html" rel="nofollow" title="Neural Approaches for 3D Pose Estimation from 3D Data">
                                            <strong>Neural Approaches for 3D Pose Estimation from 3D Data</strong></a>
                                    </h3>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>Gali Hod, Tal Barami, Michael Kolomenkin</p>
                                        <p>We present two novel, open-source methods for human pose estimation directly from 3D point clouds and meshes, enabling accurate reconstruction of body joints for use in creative, clinical, and interactive applications.
                                            Unlike classical approaches, our methods are fully differentiable and designed to integrate seamlessly into modern deep learning pipelines.
                                            One approach uses body-part segmentation for skeleton construction; the other directly estimates joint positions using a PointNet++-based neural network.</p>
                                    </div>
                                </div>
                            </article>
                            <!-- End of 3D Pose Estimation from 3D Data project -->

                            <!-- Sensperience project -->
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo-blank">
                                        <svg aria-hidden="true" class="svg-icon iconProfileArticle" width="24"
                                             height="24" viewBox="0 0 24 24">
                                            <path class="st0"
                                                  d="M13,3v6h6L13,3z M13,11c-1.1,0-2-0.9-2-2V2H5C4.5,2,4,2.5,4,3v18c0,0.5,0.5,1,1,1h14c0.5,0,1-0.5,1-1V11H13z">
                                            </path>
                                        </svg>
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="https://github.com/TalBarami/Senseperience" rel="nofollow" title="Sensperience: A Virtual Reality Journey Through Altered Perception">
                                            <strong>Sensperience: A Virtual Reality Journey Through Altered Perception</strong></a>
                                    </h3>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>Tal Barami, Liza Fridman, Carmel Lederer, Boaz Krysler</p>
                                        <p>Sensperience is an immersive virtual reality application designed to let users explore and experience a wide range of altered sensory realities.
                                            The system combines a VR headset with a Geomagic haptic device, creating a fully interactive, multi-sensory environment that can be entirely controlled and customized by the developer.

                                            Users are guided through a series of simulated scenes, each engineered to manipulate and challenge specific human senses.
                                            These scenarios include experiences such as complete darkness, underwater immersion, vertigo, zero gravity, and interaction with varied textures—all designed to evoke different perceptual and physical responses.

                                            The result is a holistic simulation platform that provides both visual and tactile feedback, enabling applications in education, therapy, training, and entertainment.
                                            Sensperience offers developers a unique sandbox to create and experiment with customized sensory manipulations in a controlled, virtual setting.</p>
                                    </div>
                                </div>
                            </article>
                            <!-- End of Sensperience project -->
                        </div>
                    </section>
                </div>
                <div class="g-col g-column cv-story">
                    <section class="g-row fl-none g-column cv-section" id="Professional Experience">
                        <header class="g-col fl-none">
                            <h2 class="fs-category">Professional Experience</h2>
                        </header>
                        <div class="g-column _gutters-24">
                            <article class="g-col g-row cv-story-item highlight">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="playtika.svg" role="img" class="cv-image" title="Playtika">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading"><strong>Researcher</strong>
                                    </h3>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Playtika</h4>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>2021 &mdash; 2022: Playtika Research Group: Pursued the field of feature disentanglement in generative methods for 3D modeling. Developed a segmentation-based method for 3D pose estimation.</p>
										<p>2019 &mdash; 2021: Data Scientist: Developed models for uplift modeling and churn predictions, as well as internal tools for the automation of research phases such as data acquisition, modeling, analysis, and evaluation.</p>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
										<span class="post-tag">Python</span>
                                        <span class="post-tag">Research</span>
                                        <span class="post-tag">Data Science</span>
                                        <span class="post-tag">3D Modeling</span>
                                        <span class="post-tag">GANs</span>
										<span class="post-tag">Pose Estimation</span>
										<span class="post-tag">Uplift Modeling</span>
										<span class="post-tag">Churn Prediction</span>
                                    </div>
                                </div>
                            </article>
                            <article class="g-col g-row cv-story-item highlight">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="mentor_graphics.svg" role="img" class="cv-image" title="Mentor Graphics">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading"><strong>Software Engineer</strong></h3>
                                    <h4 class="g-col fl-none fs-body2 fc-medium cv-item-subtitle">Mentor Graphics</h4>
                                    <div class="fs-body1 cv-item-copy">
                                        <p>2016 &mdash; 2018: Development and maintenance of features for some of the company's top products. Both handle production-line management for large-scale factories around the globe.</p>
                                    </div>
                                    <div class="g-col g-row fl-none ff-row-wrap">
                                        <span class="post-tag">Java</span>
										<span class="post-tag">Spring</span>
										<span class="post-tag">C#</span>
                                        <span class="post-tag">.NET</span>
                                        <span class="post-tag">R&D</span>

                                    </div>
                                </div>
                            </article>
                        </div>
                    </section>
                    <section class="g-col fl-none g-column cv-section" id="Teaching">
                        <header class="g-col fl-none">
                            <h2 class="fs-category">Teaching</h2>
                        </header>
                        <div class="g-column _gutters-24">
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="teaching.svg" role="img" class="cv-image" title="Mentor Graphics">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="fvm221syllabus.pdf" rel="nofollow"
                                            title="Introduction to Formal Verification Methods"><strong>Introduction to Formal Verification Methods</strong></a>
                                    </h3>
                                </div>
                            </article>
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="teaching.svg" role="img" class="cv-image" title="Mentor Graphics">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="poop222syllabus.pdf" rel="nofollow"
                                            title="Principles of Object-Oriented Programming"><strong>Principles of Object-Oriented Programming</strong></a>
                                    </h3>
                                </div>
                            </article>
                            <article class="g-col g-row cv-story-item highlight first">
                                <div class="g-column fl-none">
                                    <div class="g-center cv-logo">
                                        <img src="teaching.svg" role="img" class="cv-image" title="Mentor Graphics">
                                    </div>
                                </div>
                                <div class="g-col g-column cv-item">
                                    <h3 class="g-col fl-none fs-subheading cv-item-title">
                                        <a href="comp191syllabus.pdf" rel="nofollow"
                                            title="Compiler Principles"><strong>Compiler Principles</strong></a>
                                    </h3>
                                </div>
                            </article>
                        </div>
                    </section>
                </div>
            </div>
        </div>
    </div>
    </div>
    </div>
</body>

</html>
